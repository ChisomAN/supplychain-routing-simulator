{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6a6eb3",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "BASE = '.'\n",
    "ART_DIR = os.path.join(BASE, 'artifacts')\n",
    "DATA_DIR = os.path.join(ART_DIR, 'datasets')\n",
    "LOG_DIR = os.path.join(ART_DIR, 'logs')\n",
    "for d in [ART_DIR, DATA_DIR, LOG_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4dba34",
   "metadata": {},
   "source": [
    "## Load — From File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'sample_edges.csv'  # replace with your CSV path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "len(df), df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990473c1",
   "metadata": {},
   "source": [
    "## Load — From URL (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://raw.githubusercontent.com/plotly/datasets/master/2014_usa_states.csv'  # example CSV\n",
    "# df = pd.read_csv(url)  # uncomment to test if internet is available\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba91b76",
   "metadata": {},
   "source": [
    "## Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'distance_km'\n",
    "plt.figure()\n",
    "df[col].hist(bins=30)\n",
    "plt.title(f'Distribution of {col}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3464c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 'distance_km', 'travel_time_est'\n",
    "plt.figure()\n",
    "plt.scatter(df[x], df[y])\n",
    "plt.title(f'{x} vs {y}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8412f",
   "metadata": {},
   "source": [
    "## Cleaning & Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = df.copy()\n",
    "drop_na, cap_iqr, normalize = False, True, True\n",
    "if drop_na:\n",
    "    clean = clean.dropna()\n",
    "for c in ['distance_km', 'travel_time_est', 'fuel_rate']:\n",
    "    if c in clean.columns:\n",
    "        q1, q3 = clean[c].quantile([0.25, 0.75])\n",
    "        iqr = q3-q1\n",
    "        lo, hi = q1-1.5*iqr, q3+1.5*iqr\n",
    "        clean[c] = clean[c].clip(lo, hi)\n",
    "num_cols = [\n",
    "    c for c in clean.columns if pd.api.types.is_numeric_dtype(clean[c])]\n",
    "if normalize and num_cols:\n",
    "    scaler = MinMaxScaler()\n",
    "    clean[num_cols] = scaler.fit_transform(clean[num_cols])\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8603502",
   "metadata": {},
   "source": [
    "## Save & Log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(DATA_DIR, f'cleaned_{int(time.time())}.csv')\n",
    "clean.to_csv(out_path, index=False)\n",
    "log = {'ts': int(time.time()), 'source': file_path,\n",
    "       'rows_in': int(len(df)), 'rows_out': int(len(clean))}\n",
    "with open(os.path.join(LOG_DIR, 'runs.jsonl'), 'a') as f:\n",
    "    f.write(json.dumps(log)+'\\n')\n",
    "out_path"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
